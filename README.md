# MCP Audit

**Are your MCP tools eating context and you don't know which ones?**

Whether you're building your own MCP servers or using Claude Code, Codex CLI, or Gemini CLI daily, mcp-audit shows you exactly where tokens goâ€”per server, per tool, in real-time. Investigate and fix context bloat and high token usage at the source.

```bash
pip install mcp-audit
```

[![PyPI version](https://img.shields.io/pypi/v/mcp-audit.svg)](https://pypi.org/project/mcp-audit/)
[![PyPI downloads](https://img.shields.io/pypi/dm/mcp-audit.svg)](https://pypi.org/project/mcp-audit/)
[![Python 3.8+](https://img.shields.io/pypi/pyversions/mcp-audit.svg)](https://pypi.org/project/mcp-audit/)
[![CI](https://img.shields.io/github/actions/workflow/status/littlebearapps/mcp-audit/ci.yml?branch=main&label=CI)](https://github.com/littlebearapps/mcp-audit/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

![MCP Audit real-time TUI showing token usage per MCP server and tool](https://raw.githubusercontent.com/littlebearapps/mcp-audit/main/docs/images/demo.gif)

> Real-time token tracking per MCP server and toolâ€”see exactly what's eating your context.

<details>
<summary><strong>ğŸ“‘ Table of Contents</strong></summary>
<br>

- [Features](#features)
- [Who Is This For?](#-who-is-this-for)
- [Why mcp-audit?](#-why-mcp-audit)
  - [How mcp-audit Compares](#how-mcp-audit-compares)
- [Quick Start](#-quick-start)
- [Platform Support](#ï¸-platform-support)
- [Feature Details](#-feature-details)
- [Configuration](#ï¸-configuration)
- [Documentation](#-documentation)
- [CLI Reference](#-cli-reference)
- [Data Storage](#-data-storage)
- [FAQ](#-faq)
- [Roadmap](#ï¸-roadmap)
- [Contributing](#-contributing)
- [License](#-license)

</details>

### Features

- âš¡ **Real-time TUI** â€” Watch tokens flow as you work
- ğŸ“Š **Per-tool breakdown** â€” Track MCP tool calls; per-tool tokens on Claude Code
- ğŸ’° **Cost estimates** â€” Know what you're paying before the bill
- ğŸ” **Anomaly detection** â€” Spot duplicates and outliers automatically
- ğŸ—„ï¸ **Cache analysis** â€” Understand if caching helps or hurts
- ğŸ”’ **Privacy-first** â€” Local-only, no prompts stored
- ğŸª¶ **Lightweight** â€” <500KB install, single dependency (rich)

---

## ğŸ‘¥ Who Is This For?

<table>
<tr>
<td width="50%" valign="top">

### ğŸ› ï¸ MCP Tool Developers

You built an MCP server. Now you need answers:
- How efficient are my tools?
- Which ones bloat context?
- Am I shipping something optimized?

</td>
<td width="50%" valign="top">

### ğŸ’» Daily Users (Power Users)

You use Claude Code, Codex CLI, or Gemini CLI daily:
- Hit context limits and don't know why?
- Seeing unexpected costs?
- Which MCP servers are responsible?

</td>
</tr>
</table>

---

## ğŸ’¡ Why mcp-audit?

**mcp-audit** is a real-time session tracker that shows you which MCP tools are being called, with full per-tool token attribution on Claude Code and call-count tracking across all platforms. Whether you're building MCP servers or using them daily, mcp-audit gives you the data you need to investigate and fix context bloat & high token usage at the source.

No other tool provides this level of MCP-specific visibility. It starts with the data.

---

### How mcp-audit Compares

#### vs. [ccusage](https://github.com/ryoppippi/ccusage) â­ 9K+

ccusage is a fantastic **historical analyzer**â€”it tracks your Claude Code usage over time (daily, monthly, all-time reports). Use it to understand long-term spending trends and budget planning.

| | ccusage | mcp-audit âœ“ |
|---|---------|:------------|
| **Focus** | Historical trends | âœ… Real-time sessions |
| **Question answered** | "What did I spend this month?" | âœ… "What's eating my context *right now*?" |
| **Granularity** | Session/day/month totals | âœ… Per-MCP-server, per-tool breakdownÂ¹ |
| **Best for** | Cost tracking over time | âœ… Investigating specific tool issues |

#### vs. [Claude-Code-Usage-Monitor](https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor) â­ 5.8K+

Claude-Code-Usage-Monitor is a great **session limit tracker**â€”it predicts when you'll hit your token limit and shows burn rate. Use it to manage your session pacing.

| | Claude-Code-Usage-Monitor | mcp-audit âœ“ |
|---|---------------------------|:------------|
| **Focus** | Session limits & predictions | âœ… MCP tool analysis |
| **Question answered** | "Will I run out of tokens?" | âœ… "Which MCP tool is causing this?" |
| **Granularity** | Total session tokens | âœ… Per-server, per-tool breakdownÂ¹ |
| **Best for** | Session pacing | âœ… Debugging MCP tool efficiency |

> Â¹ Per-tool token breakdown requires Claude Code. Codex CLI and Gemini CLI provide call counts with session-level token totals.

#### Why mcp-audit for MCP Tool Development

If you're **building or optimizing MCP servers**, mcp-audit is the only tool that:

- ğŸ” **Breaks down tokens per MCP tool** â€” See exactly which tools bloat context (Claude Code)
- ğŸ“Œ **Pins specific servers** â€” Monitor your server while you develop
- ğŸ”„ **Detects duplicates** â€” Find redundant tool calls automatically
- ğŸ“Š **Tracks cache efficiency** â€” Understand if caching helps or hurts
- ğŸš¨ **Flags anomalies** â€” Get warnings for high-variance patterns
- ğŸ“ˆ **Counts all tool calls** â€” Track MCP usage across all platforms

> [!TIP]
> **Use them together**: ccusage for monthly cost trends, Claude-Code-Usage-Monitor for session pacing, and mcp-audit for MCP tool-level investigation.

---

## ğŸš€ Quick Start

### 1. Track a Session

```bash
# Track Claude Code session
mcp-audit collect --platform claude-code

# Track Codex CLI session
mcp-audit collect --platform codex-cli

# Track Gemini CLI session
mcp-audit collect --platform gemini-cli
```

Sessions are automatically saved to `~/.mcp-audit/sessions/`.

### 2. Generate a Report

```bash
# View summary of all sessions
mcp-audit report ~/.mcp-audit/sessions/

# Export detailed CSV
mcp-audit report ~/.mcp-audit/sessions/ --format csv --output report.csv

# Generate markdown report
mcp-audit report ~/.mcp-audit/sessions/ --format markdown --output report.md
```

### 3. Review Results

```
Top 10 Most Expensive Tools (Total Tokens)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Tool                              Calls    Tokens    Avg/Call
mcp__zen__thinkdeep                  12   450,231      37,519
mcp__brave-search__web               45   123,456       2,743
mcp__zen__chat                       89    98,765       1,109

Estimated Total Cost: $2.34 (across 15 sessions)
```

> Per-tool token breakdown shown above is from Claude Code sessions. Codex CLI and Gemini CLI reports show call counts with session-level totals.

### Typical Session

```bash
# Terminal 1: Start tracking before your Claude Code session
mcp-audit collect --platform claude-code

# Terminal 2: Work normally in Claude Code
# (TUI shows tokens accumulating in real-time as you use MCP tools)

# When done, press Ctrl+C in Terminal 1
# Session auto-saved to ~/.mcp-audit/sessions/
```

---

## ğŸ–¥ï¸ Platform Support

| Platform | Status | Token Tracking | What You Get |
|----------|--------|----------------|--------------|
| Claude Code | **Stable** | Full (per-tool) | Per-tool token attribution, cache analysis |
| Codex CLI | **Stable** | Session-level | Call counts, session costs, reasoning tokensÂ² |
| Gemini CLI | **Stable** | Session-level | Call counts, session costs, reasoning tokensÂ² |
| Ollama CLI | *Coming Soon* | Time-based | Duration tracking (no token costs locally) |

> **Note**: Per-tool token attribution is a Claude Code exclusive. Codex CLI and Gemini CLI provide accurate session totals with tool call countsâ€”still unique visibility no other tool offers.
>
> Â² Reasoning tokens (thinking/chain-of-thought) tracked separately for o-series (Codex) and Gemini 2.0+ models.

<details>
<summary><strong>Detailed Platform Capabilities</strong></summary>
<br>

| Capability | Claude Code | Codex CLI | Gemini CLI |
|------------|:-----------:|:---------:|:----------:|
| Session tokens | âœ… Full | âœ… Full | âœ… Full |
| Per-tool tokens | âœ… Native | âŒ Calls only | âŒ Calls only |
| Reasoning tokens | âŒ Not exposed | âœ… o-series | âœ… Gemini 2.0+ |
| Cache tracking | âœ… Create + Read | âœ… Read only | âœ… Read only |
| Built-in tools | âœ… Calls + Tokens | âœ… Calls only | âœ… Calls only |
| Cost estimates | âœ… Accurate | âœ… Accurate | âœ… Accurate |
| MCP server breakdown | âœ… Full | âœ… Calls only | âœ… Calls only |

Claude Code provides the richest data. For Codex CLI and Gemini CLI, mcp-audit tracks what the platforms expose: session totals, call counts, and cost estimates.

</details>

Want support for another CLI platform? Have a feature request? [Start a discussion](https://github.com/littlebearapps/mcp-audit/discussions)!

---

## âœ¨ Feature Details

### âš¡ Real-Time TUI

Watch tokens flow as you workâ€”no manual tracking:

```
MCP Audit v0.3.14
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Project: my-project â”‚ Claude Opus 4.5 â”‚ 12m 34s

Tokens
  Input: 45,231 â”‚ Output: 12,543 â”‚ Cache: 125K (93%)
  Cost: $0.12 â”‚ Cache Savings: $0.89

MCP Servers & Tools (42 calls)
  zen (28 calls, 234K tokens)
    thinkdeep ........ 8 calls, 156K tokens
    chat ............. 15 calls, 45K tokens
  brave-search (14 calls, 89K tokens)
    brave_web_search . 14 calls, 89K tokens
```

> The TUI above shows Claude Code output with full per-tool token attribution. On Codex CLI and Gemini CLI, token columns show call counts only (per-tool tokens are a platform limitation).

**Investigating context bloat?** Pin your MCP server to monitor it closely during development:

```bash
mcp-audit collect --platform claude-code --pin-server myserver
```

### ğŸ“Š Cross-Session Analysis

Aggregate insights across all your sessions:

```bash
mcp-audit report ~/.mcp-audit/sessions/ --aggregate
```

- Top expensive tools by total tokens
- Most frequently called tools
- Anomaly detection (high variance, duplicates)
- Per-server cost breakdowns

### ğŸ” Duplicate Detection

Spot wasted tokens from redundant tool calls:

```json
{
  "redundancy_analysis": {
    "duplicate_calls": 3,
    "potential_savings": 15234
  }
}
```

### ğŸ—„ï¸ Cache Analysis

Understand whether caching is helping or hurting. Session logs include AI-readable insights:

```json
{
  "cache_analysis": {
    "status": "efficient",
    "summary": "Good cache reuse (85% efficiency). Savings: $0.89",
    "top_cache_creators": [{"tool": "mcp__zen__thinkdeep", "pct": 45}],
    "recommendation": "Cache is working well for this session."
  }
}
```

### ğŸ”’ Privacy-First

- **No prompts stored** - Only token counts and tool names
- **Local-only** - All data stays on your machine
- **Redaction hooks** - Customize what gets logged

---

## âš™ï¸ Configuration

Customize model pricing in `mcp-audit.toml`. Searched in order: `./mcp-audit.toml` (project), `~/.mcp-audit/mcp-audit.toml` (user).

> [!NOTE]
> Prices in **USD per million tokens**.

```toml
[pricing.claude]
"claude-opus-4-5-20251101" = { input = 5.00, output = 25.00, cache_create = 6.25, cache_read = 0.50 }
"claude-sonnet-4-5-20250929" = { input = 3.00, output = 15.00, cache_create = 3.75, cache_read = 0.30 }

[pricing.openai]
"gpt-5.1" = { input = 1.25, output = 10.00, cache_read = 0.125 }
"gpt-4o" = { input = 2.50, output = 10.00, cache_read = 1.25 }

[pricing.gemini]
"gemini-3-pro-preview" = { input = 2.00, output = 12.00, cache_read = 0.20 }
"gemini-2.5-pro" = { input = 1.25, output = 10.00, cache_read = 0.125 }
"gemini-2.5-flash" = { input = 0.30, output = 2.50, cache_read = 0.03 }
```

See [Pricing Configuration](docs/PRICING-CONFIGURATION.md) for the full list of supported models.

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Features & Benefits](docs/FEATURES-BENEFITS.md) | Detailed feature guide by audience |
| [Architecture](docs/architecture.md) | System design, data model, adapters |
| [Data Contract](docs/data-contract.md) | Schema v1.3.0 format and guarantees |
| [Platform Guides](docs/platforms/) | Claude Code, Codex CLI, Gemini CLI setup |
| [Contributing](docs/contributing.md) | How to add platform adapters |
| [Privacy & Security](docs/privacy-security.md) | Data handling policies |
| [Changelog](CHANGELOG.md) | Version history and release notes |
| [Roadmap](ROADMAP.md) | Planned features and long-term vision |

---

## ğŸ’» CLI Reference

```bash
mcp-audit --help

Commands:
  collect   Track a live session
  report    Generate usage report

Options:
  --version  Show version
  --help     Show help
```

### collect

```bash
mcp-audit collect [OPTIONS]

Options:
  --platform          Platform to track (claude-code, codex-cli, gemini-cli, auto)
  --project TEXT      Project name (auto-detected from directory)
  --output PATH       Output directory (default: ~/.mcp-audit/sessions)
  --tui               Use rich TUI display (default when TTY available)
  --plain             Use plain text output (for CI/logs)
  --quiet             Suppress all display output (logs only)
  --refresh-rate NUM  TUI refresh rate in seconds (default: 0.5)
  --pin-server NAME   Pin server(s) at top of MCP section (can repeat)
  --no-logs           Skip writing logs to disk (real-time display only)
  --from-start        Include existing session data (Codex/Gemini CLI only)
```

> **Note**: For Codex CLI and Gemini CLI, mcp-audit tracks only **new** events by default. Use `--from-start` to include events from before tracking started.

#### Display Modes

MCP Audit automatically detects whether you're running in a terminal (TTY) and chooses the best display mode:

- **TUI mode** (default for terminals): Beautiful Rich-based dashboard with live updating
- **Plain mode** (default for CI/pipes): Simple scrolling text output
- **Quiet mode**: No display output, only writes logs to disk

### report

```bash
mcp-audit report [OPTIONS] SESSION_DIR

Arguments:
  SESSION_DIR        Session directory or parent directory containing sessions

Options:
  --format           Output format: json, csv, markdown (default: markdown)
  --output PATH      Output file (default: stdout)
  --aggregate        Aggregate data across multiple sessions
  --top-n INT        Number of top tools to show (default: 10)
```

---

## ğŸ“ Data Storage

Sessions are stored at `~/.mcp-audit/sessions/` organized by platform and date:

```
~/.mcp-audit/sessions/
â”œâ”€â”€ claude-code/
â”‚   â””â”€â”€ 2025-12-04/
â”‚       â””â”€â”€ my-project-2025-12-04T09-15-30.json
â”œâ”€â”€ codex-cli/
â”‚   â””â”€â”€ 2025-12-04/
â”‚       â””â”€â”€ seo-expert-2025-12-04T11-36-54.json
â””â”€â”€ gemini-cli/
    â””â”€â”€ 2025-12-04/
        â””â”€â”€ research-2025-12-04T14-20-00.json
```

Each session is a self-describing JSON file (schema v1.3.0). See [Data Contract](docs/data-contract.md) for format details.

---

## â“ FAQ

<details open>
<summary><strong>Does mcp-audit work with resumed/continued sessions?</strong></summary>
<br>

**Yes.** If you start mcp-audit and then resume a Claude Code session from yesterday, it will track all new activity from that point forward. Claude Code appends new events to the existing session file, and mcp-audit monitors for new content regardless of when the session originally started.

</details>

<details>
<summary><strong>What if I start mcp-audit after Claude Code is already running?</strong></summary>
<br>

**It works, but you'll only capture activity from that point forward.** When mcp-audit starts, it records the current position in all session files. Any new events written after that point are tracked. Events that occurred before you started mcp-audit are not captured.

> [!TIP]
> Start mcp-audit first, then start or resume your Claude Code session.

</details>

<details>
<summary><strong>Does mcp-audit track historical data or only new activity?</strong></summary>
<br>

**Only new activity.** mcp-audit is designed for real-time monitoring. It deliberately skips historical data to avoid:
- Re-processing old sessions you've already analyzed
- Inflating token counts with past activity
- Confusion about what happened "this session" vs "last week"

If you need to analyze historical sessions, use `mcp-audit report` on previously saved session files.

</details>

<details>
<summary><strong>Can I track multiple Claude Code windows or projects?</strong></summary>
<br>

**Yes, but each requires its own mcp-audit instance.** Each Claude Code project has its own session file in `~/.claude/projects/`. If you're working in multiple directories simultaneously:

```bash
# Terminal 1: Track project A
cd ~/projects/project-a
mcp-audit collect --platform claude-code

# Terminal 2: Track project B
cd ~/projects/project-b
mcp-audit collect --platform claude-code
```

Each mcp-audit instance monitors the session files for its working directory.

</details>

<details>
<summary><strong>Why am I seeing 0 tokens or no activity?</strong></summary>
<br>

Common causes:

1. **Started mcp-audit after Claude Code** - Only new activity is tracked. Try making a request in Claude Code after starting mcp-audit.

2. **Wrong directory** - mcp-audit looks for session files based on your working directory. Make sure you're in the same directory as your Claude Code session.

3. **No MCP tools used** - mcp-audit tracks MCP server tools (like `mcp__zen__chat`). Built-in tools (Read, Write, Bash) are tracked separately. If you're not using MCP tools, you'll see low/zero MCP activity.

4. **Session file not found** - Check that Claude Code has created a session file:
   ```bash
   ls ~/.claude/projects/
   ```

5. **Platform limitation (Codex/Gemini)** - Codex CLI and Gemini CLI don't provide per-tool token attribution. You'll see accurate session totals and call counts, but individual tool token columns will show 0. This is expected behavior, not a bug.

</details>

<details>
<summary><strong>Where is my data stored? Is it sent anywhere?</strong></summary>
<br>

**All data stays on your machine.** mcp-audit is completely local:

- Session data: `~/.mcp-audit/sessions/`
- Configuration: `~/.mcp-audit/mcp-audit.toml`
- No network requests, no telemetry, no cloud sync

Only token counts and tool names are loggedâ€”**prompts and responses are never stored**.

</details>

<details>
<summary><strong>How do I stop tracking without losing data?</strong></summary>
<br>

**Press Ctrl+C.** mcp-audit handles interrupts gracefully:

1. Catches the interrupt signal
2. Completes the session summary
3. Writes all data to disk
4. Exits cleanly

You'll see a confirmation message:
```
Session saved to: ~/.mcp-audit/sessions/2025-12-02/mcp-audit-2025-12-02T14-30-45.json
```

> [!WARNING]
> Avoid `kill -9` or force-quitting the terminal, which may result in incomplete session data.

</details>

<details>
<summary><strong>Can I track multiple platforms at the same time?</strong></summary>
<br>

**Yes.** Run separate mcp-audit instances for each platform:

```bash
# Terminal 1: Track Claude Code
mcp-audit collect --platform claude-code

# Terminal 2: Track Codex CLI
mcp-audit collect --platform codex-cli
```

Sessions are organized by date in `~/.mcp-audit/sessions/`.

</details>

---

## ğŸ—ºï¸ Roadmap

**Current**: v0.3.x (Beta) â€” Stable for daily use

### Coming Soon
- Multi-model session tracking
- Enhanced CLI commands and report filters
- Ollama CLI support (local models)
- Dynamic pricing via LiteLLM

See the full [Roadmap](ROADMAP.md) for details and long-term vision.

**Have an idea?** [Start a discussion](https://github.com/littlebearapps/mcp-audit/discussions/new?category=ideas) â€” we'd love to hear from you!

---

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for:

- How to add new platform adapters
- Testing requirements
- PR workflow

### Development Setup

```bash
git clone https://github.com/littlebearapps/mcp-audit.git
cd mcp-audit
python -m venv venv
source venv/bin/activate
pip install -e ".[dev]"
pytest
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

ğŸ» **Made with care by [Little Bear Apps](https://littlebearapps.com)**

[Issues](https://github.com/littlebearapps/mcp-audit/issues) Â· [Discussions](https://github.com/littlebearapps/mcp-audit/discussions) Â· [Roadmap](ROADMAP.md)
